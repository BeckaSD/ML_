# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Y3hQqNTZQV1PVIkd4uDzIBOTcLOfcytb
"""

!pip install panda

!pip install numpy
!pip install matplotlib
!pip install scikit-learn

!pip install matplotlib
!pip install seaborn

from sklearn.metrics import roc_curve,auc,confusion_matrix
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC,SVC
from sklearn.model_selection import train_test_split,GridSearchCV

from sklearn.preprocessing import StandardScaler

import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

"""**Data analysis**"""

df=pd.read_csv("/content/diabetes.csv")

df.describe()

df.info()

df.nunique()

df=df.rename(columns={"Outcome":"target"})

df

df.isnull().sum()

plt.figure(figsize=(10, 8))
sns.heatmap(df.corr())

sns.pairplot(df)

X=df.iloc[:,:-1].values
X

Y=df.iloc[:,-1].values

from imblearn.over_sampling import RandomOverSampler
r=RandomOverSampler()
x_data,y_data=r.fit_resample(X,Y)

s=StandardScaler()
x_std=s.fit_transform(X)

from sklearn import model_selection
L=[]
for i in range (0,1000):
  x_train,x_test,y_train,y_test=train_test_split(x_std,Y,test_size=0.2,random_state=i)
  lr.fit(x_train,y_train)
  y_pred=lr.predict(x_test)
  mse = mean_squared_error(y_test, y_pred)
  rmse = np.sqrt(mse)
  a={"random_n":i,"rmse":np.round(rmse, 2),"score_train":lr.score(x_train,y_train).round(4),"score_test":lr.score(x_test,y_test).round(4)}
  L.append(a)

a=L[0]["score_test"]
b=0
c=0
for i  in range(0,len(L)):
  if(i!=len(L)-1):  
    if(L[i+1]["score_test"]>a):
      a=L[i+1]["score_test"]
      b=i+1
print(b)

L[142]

x_train,x_test,y_train,y_test=train_test_split(x_std,Y,test_size=0.2,random_state=142)

lr=LogisticRegression()

lr.fit(x_train,y_train)



from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
print("RMSE: ", np.round(rmse, 2))

y_pred=lr.predict(x_test)

pd.Series(y_pred).value_counts()

def score(estimator):
  tr_scor=estimator.score(x_train,y_train).round(4)
  te_scor=estimator.score(x_test,y_test).round(4)
  return(f"train;{tr_scor} test:{te_scor}")

score(lr)

def confus(estimator): 
  mat=confusion_matrix(y_test,y_pred)
  mat=pd.DataFrame(mat)
  mat.columns=[f'pred_{i}' for i in mat.columns]
  mat.index=[f'test_{i}'for i in mat.index]
  return mat

confus(lr)

import numpy as np
lr=LogisticRegression()
parlm={'C':np.logspace(-3,3,7),
       'penalty':["l1", "l2", "elasticnet", None],
       "random_state":[142,None],
       'solver':['newton-cg','lbfgs','liblinear', 'newton-cholesky', 'sag', 'saga',None]
       }

grid=GridSearchCV(lr,parlm,cv=15,n_jobs=-1,return_train_score=True,verbose=1)

grid.fit(x_train,y_train)

lr.get_params().keys()



res=pd.DataFrame(grid.cv_results_)
res

lr=LogisticRegression(**grid.best_params_)

lr.fit(x_train,y_train)

score(lr)

"""**SVC**"""

from sklearn import model_selection
L=[]
for i in range (0,1000):
  x_train,x_test,y_train,y_test=train_test_split(x_std,Y,test_size=0.2,random_state=i)
  svc.fit(x_train,y_train)
  y_pred=svc.predict(x_test)
  mse = mean_squared_error(y_test, y_pred)
  rmse = np.sqrt(mse)
  a={"random_n":i,"rmse":np.round(rmse, 2),"score_train":svc.score(x_train,y_train).round(4),"score_test":svc.score(x_test,y_test).round(4)}
  L.append(a)

a=L[0]["score_test"]
b=0
c=0
for i  in range(0,len(L)):
  if(i!=len(L)-1):  
    if(L[i+1]["score_test"]>a):
      a=L[i+1]["score_test"]
      b=i+1
print(b)

L[142]

x_train,x_test,y_train,y_test=train_test_split(x_std,Y,test_size=0.2,random_state=142)

svc=LinearSVC()

svc.fit(x_train,y_train)

y_pred=svc.predict(x_test)

score(svc)

confus(svc)

import numpy as np
svcg=LinearSVC()
parlm={'C':[0.1,1, 10, 100],
       'kernel':['linear', 'poly', 'rbf', 'sigmoid'],
       'gamma':[1,0.1,0.01,0.001],
       'decision_function_shape':['ovo', 'ovr'],
       
       }

param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}
grid1 = GridSearchCV(SVC(),parlm, cv=10,refit=True,verbose=2)
grid1.fit(x_train,y_train)

grid=GridSearchCV(svcg,param_grid, n_jobs=-1, cv=10, verbose=1, return_train_score=False)

grid1.best_params_

grid.fit(x_train,y_train)

sv=SVC(C=100,gamma=0.001,kernel='sigmoid')

sv.fit(x_train,y_train)

grid1.best_params_

y_pred=sv.predict(x_test)

score(sv)